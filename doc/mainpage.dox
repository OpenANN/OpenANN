namespace OpenANN
{

/**

\image html openann-logo.svg

\mainpage %OpenANN

This is the API documentation of %OpenANN.

%OpenANN is an open source library for artificial neural networks. It is open
for users that want to apply ANN to their problems, developers and researchers
that want to implement new technologies and students that want to understand
the tricks that are required to implement neural networks. It follows a
minimal dependency policy, i.e. we rely on only a few libraries and tools.

To start using %OpenANN it might be helpful to take a look at
\ref GettingStarted to see how it works.

\section Documentation

\subsection Quickstart
  - \ref Installation
  - \ref GettingStarted

\subsection Tutorials
  - \ref CreateDataSet
  - \ref HowtoLearn
  - \ref Convenience
  - \ref Architecture
  - \ref Logging

\subsection Advanced
  - \ref Benchmarks
  - \ref OtherLibs
  - \ref Contributing

\section Features

- Various types of artificial neural networks
  - Multilayer neural network
  - %Convolutional neural network (CNN) with convolutional layers,
    subsampling layers and max-pooling layers
  - Random projections for data and network compression and extreme learning
    machines
  - Restricted Boltzmann machines (RBM) for unsupervised pretraining
- Optimization algorithms
  - Mini-batch stochastic gradient descent (MBSGD) for large networks
  - Conjugate gradient (CG) for large networks
  - Limited storage Broyden-Fletcher-Goldfarb-Shanno (LBFGS) for networks of
    medium size
  - Levenberg-Marquardt algorithm (LMA) for small networks
  - (Increasing population size) covariance matrix adaption evolution
    strategies (IPOPCMAES) for reinforcement learning
- Supported languages
  - C++
  - Python bindings

\section Applications

%OpenANN has been used to

- develop a new network compression technique based on compressed sensing that
can be used for supervised as well as for reinforcement learning [1]
- examine invariant pattern recognition approaches with constrained higher
order nodes

[1] A. Fabisch, Y. Kassahun, H. WÃ¶hrle and F. Kirchner:
Learning in compressed space,
Neural Networks 42, pp. 83-93, ISSN 0893-6080, 2013.

\section License

The license is LGPL 3. You can find the license text in the files COPYING and
COPYING.LESSER.

*/

}
